{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b019dd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pronouncing in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: cmudict>=0.4.0 in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (from pronouncing) (1.0.2)\n",
      "Requirement already satisfied: kaggle in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (1.5.12)\n",
      "Requirement already satisfied: certifi in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (from kaggle) (2020.12.5)\n",
      "Requirement already satisfied: urllib3 in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (from kaggle) (1.26.4)\n",
      "Requirement already satisfied: tqdm in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (from kaggle) (4.59.0)\n",
      "Requirement already satisfied: requests in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: six>=1.10 in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: python-slugify in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (from requests->kaggle) (4.0.0)\n",
      "Requirement already satisfied: markovify in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (0.9.3)\n",
      "Requirement already satisfied: unidecode in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (from markovify) (1.3.2)\n",
      "Requirement already satisfied: textstat in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (0.7.2)\n",
      "Requirement already satisfied: pyphen in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (from textstat) (0.11.0)\n",
      "Requirement already satisfied: better-profanity in /Users/ganymede/opt/anaconda3/lib/python3.8/site-packages (0.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pronouncing\n",
    "!pip3 install markovify\n",
    "!pip3 install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f147e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, SimpleRNN, LSTM, GRU, Conv1D, Embedding, Dense, Bidirectional, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from better_profanity import profanity\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random as rand\n",
    "import numpy as np\n",
    "import pronouncing\n",
    "import markovify\n",
    "import textstat\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2562cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_file = \"./data/Drake_lyrics.txt\"\n",
    "artist_lyrics = []\n",
    "\n",
    "with open(artist_file, \"r\") as file:\n",
    "    song = profanity.censor(file.read())\n",
    "    artist_lyrics = song.replace('\\ufeff', '').split(\"\\n\")\n",
    "\n",
    "print(artist_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a1d27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_model = markovify.NewlineText(str(\"\\n\".join(artist_lyrics)), well_formed=False, state_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9816db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back to back, like I'm on the road right now swangin, girl\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "sentence = markov_model.make_sentence(tries=100)\n",
    "\n",
    "print(sentence)\n",
    "\n",
    "# Test out the readability index\n",
    "print(textstat.automated_readability_index(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a93d6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4244, 29) (4244, 3307)\n"
     ]
    }
   ],
   "source": [
    "# Train datasets\n",
    "sequences = artist_lyrics\n",
    "\n",
    "# Tokenize for TensorFlow\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "V = len(tokenizer.word_index)+1\n",
    "\n",
    "# Pad the sequences\n",
    "seq = pad_sequences(tokenizer.texts_to_sequences(sequences), maxlen=30)\n",
    "\n",
    "# Split to X/y data\n",
    "train_X, train_y = seq[:, :-1], tf.keras.utils.to_categorical(seq[:, -1], num_classes=V)\n",
    "\n",
    "print(train_X.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8358a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 29, 512)           1693184   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 150)               99450     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3307)              499357    \n",
      "=================================================================\n",
      "Total params: 2,291,991\n",
      "Trainable params: 2,291,991\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "133/133 [==============================] - 15s 92ms/step - loss: 6.6316 - accuracy: 0.0994\n",
      "Epoch 2/50\n",
      "133/133 [==============================] - 17s 127ms/step - loss: 5.4728 - accuracy: 0.1383\n",
      "Epoch 3/50\n",
      "133/133 [==============================] - 15s 109ms/step - loss: 4.8706 - accuracy: 0.2024\n",
      "Epoch 4/50\n",
      "133/133 [==============================] - 14s 104ms/step - loss: 4.2040 - accuracy: 0.2983\n",
      "Epoch 5/50\n",
      "133/133 [==============================] - 12s 93ms/step - loss: 3.5898 - accuracy: 0.3827\n",
      "Epoch 6/50\n",
      "133/133 [==============================] - 11s 83ms/step - loss: 2.9893 - accuracy: 0.4651\n",
      "Epoch 7/50\n",
      "133/133 [==============================] - 15s 114ms/step - loss: 2.4543 - accuracy: 0.5573\n",
      "Epoch 8/50\n",
      "133/133 [==============================] - 13s 96ms/step - loss: 1.9859 - accuracy: 0.6616\n",
      "Epoch 9/50\n",
      "133/133 [==============================] - 17s 129ms/step - loss: 1.5748 - accuracy: 0.7719\n",
      "Epoch 10/50\n",
      "133/133 [==============================] - 11s 82ms/step - loss: 1.2198 - accuracy: 0.8570\n",
      "Epoch 11/50\n",
      "133/133 [==============================] - 15s 109ms/step - loss: 0.9320 - accuracy: 0.9112\n",
      "Epoch 12/50\n",
      "133/133 [==============================] - 11s 86ms/step - loss: 0.6966 - accuracy: 0.9402\n",
      "Epoch 13/50\n",
      "133/133 [==============================] - 12s 94ms/step - loss: 0.5254 - accuracy: 0.9604\n",
      "Epoch 14/50\n",
      "133/133 [==============================] - 12s 90ms/step - loss: 0.4020 - accuracy: 0.9717\n",
      "Epoch 15/50\n",
      "133/133 [==============================] - 16s 121ms/step - loss: 0.3168 - accuracy: 0.9764\n",
      "Epoch 16/50\n",
      "133/133 [==============================] - 14s 102ms/step - loss: 0.2584 - accuracy: 0.9811\n",
      "Epoch 17/50\n",
      "133/133 [==============================] - 13s 100ms/step - loss: 0.2148 - accuracy: 0.9842\n",
      "Epoch 18/50\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.1853 - accuracy: 0.9835\n",
      "Epoch 19/50\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.1616 - accuracy: 0.9854\n",
      "Epoch 20/50\n",
      "133/133 [==============================] - 11s 84ms/step - loss: 0.1445 - accuracy: 0.9854\n",
      "Epoch 21/50\n",
      "133/133 [==============================] - 11s 82ms/step - loss: 0.1320 - accuracy: 0.9847\n",
      "Epoch 22/50\n",
      "133/133 [==============================] - 11s 83ms/step - loss: 0.1216 - accuracy: 0.9856\n",
      "Epoch 23/50\n",
      "133/133 [==============================] - 11s 86ms/step - loss: 0.1148 - accuracy: 0.9847\n",
      "Epoch 24/50\n",
      "133/133 [==============================] - 12s 88ms/step - loss: 0.1091 - accuracy: 0.9844\n",
      "Epoch 25/50\n",
      "133/133 [==============================] - 12s 89ms/step - loss: 0.1036 - accuracy: 0.9856\n",
      "Epoch 26/50\n",
      "133/133 [==============================] - 12s 91ms/step - loss: 0.0990 - accuracy: 0.9849\n",
      "Epoch 27/50\n",
      "133/133 [==============================] - 11s 85ms/step - loss: 0.0948 - accuracy: 0.9854\n",
      "Epoch 28/50\n",
      "133/133 [==============================] - 12s 86ms/step - loss: 0.0927 - accuracy: 0.9859\n",
      "Epoch 29/50\n",
      "133/133 [==============================] - 11s 86ms/step - loss: 0.0899 - accuracy: 0.9844\n",
      "Epoch 30/50\n",
      "133/133 [==============================] - 12s 90ms/step - loss: 0.0872 - accuracy: 0.9859\n",
      "Epoch 31/50\n",
      "133/133 [==============================] - 12s 88ms/step - loss: 0.0850 - accuracy: 0.9849\n",
      "Epoch 32/50\n",
      "133/133 [==============================] - 13s 98ms/step - loss: 0.0846 - accuracy: 0.9847\n",
      "Epoch 33/50\n",
      "133/133 [==============================] - 13s 96ms/step - loss: 0.0823 - accuracy: 0.9859\n",
      "Epoch 34/50\n",
      "133/133 [==============================] - 12s 88ms/step - loss: 0.0828 - accuracy: 0.9849\n",
      "Epoch 35/50\n",
      "133/133 [==============================] - 11s 85ms/step - loss: 0.0796 - accuracy: 0.9856\n",
      "Epoch 36/50\n",
      "133/133 [==============================] - 11s 85ms/step - loss: 0.0786 - accuracy: 0.9849\n",
      "Epoch 37/50\n",
      "133/133 [==============================] - 11s 84ms/step - loss: 0.0776 - accuracy: 0.9856\n",
      "Epoch 38/50\n",
      "133/133 [==============================] - 11s 84ms/step - loss: 0.0775 - accuracy: 0.9854\n",
      "Epoch 39/50\n",
      "133/133 [==============================] - 11s 83ms/step - loss: 0.0774 - accuracy: 0.9849\n",
      "Epoch 40/50\n",
      "133/133 [==============================] - 11s 84ms/step - loss: 0.0752 - accuracy: 0.9854\n",
      "Epoch 41/50\n",
      "133/133 [==============================] - 11s 86ms/step - loss: 0.0754 - accuracy: 0.9849\n",
      "Epoch 42/50\n",
      "133/133 [==============================] - 12s 86ms/step - loss: 0.0745 - accuracy: 0.9854\n",
      "Epoch 43/50\n",
      "133/133 [==============================] - 12s 88ms/step - loss: 0.0741 - accuracy: 0.9847\n",
      "Epoch 44/50\n",
      "133/133 [==============================] - 11s 83ms/step - loss: 0.0732 - accuracy: 0.9852\n",
      "Epoch 45/50\n",
      "133/133 [==============================] - 12s 86ms/step - loss: 0.0734 - accuracy: 0.9849\n",
      "Epoch 46/50\n",
      "133/133 [==============================] - 11s 86ms/step - loss: 0.0724 - accuracy: 0.9854\n",
      "Epoch 47/50\n",
      "133/133 [==============================] - 12s 89ms/step - loss: 0.0732 - accuracy: 0.9852\n",
      "Epoch 48/50\n",
      "133/133 [==============================] - 12s 89ms/step - loss: 0.0712 - accuracy: 0.9849\n",
      "Epoch 49/50\n",
      "133/133 [==============================] - 11s 84ms/step - loss: 0.0718 - accuracy: 0.9844\n",
      "Epoch 50/50\n",
      "133/133 [==============================] - 11s 83ms/step - loss: 0.0711 - accuracy: 0.9852\n"
     ]
    }
   ],
   "source": [
    "D = 512\n",
    "\n",
    "#Simple RNN\n",
    "T = train_X.shape[1]\n",
    "i = Input(shape=(T,))\n",
    "x = Embedding(V, D)(i)\n",
    "x = Dropout(0.2)(x)\n",
    "x = SimpleRNN(150)(x)\n",
    "x = Dense(V, activation=\"softmax\")(x)\n",
    "rnn_model = Model(i, x)\n",
    "rnn_model.summary()\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "rnn_model.compile(optimizer=adam, metrics=[\"accuracy\"], loss=\"categorical_crossentropy\")\n",
    "\n",
    "rnn_r = rnn_model.fit(train_X, train_y, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99649aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 29, 768)           2540544   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 29, 100)           347600    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3307)              334007    \n",
      "=================================================================\n",
      "Total params: 3,302,551\n",
      "Trainable params: 3,302,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/120\n",
      "133/133 [==============================] - 31s 194ms/step - loss: 6.7263 - accuracy: 0.0766\n",
      "Epoch 2/120\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 5.8088 - accuracy: 0.0846\n",
      "Epoch 3/120\n",
      "133/133 [==============================] - 25s 187ms/step - loss: 5.5496 - accuracy: 0.1216\n",
      "Epoch 4/120\n",
      "133/133 [==============================] - 26s 194ms/step - loss: 5.3778 - accuracy: 0.1305\n",
      "Epoch 5/120\n",
      "133/133 [==============================] - 25s 185ms/step - loss: 5.2304 - accuracy: 0.1291\n",
      "Epoch 6/120\n",
      "133/133 [==============================] - 26s 192ms/step - loss: 5.0882 - accuracy: 0.1393\n",
      "Epoch 7/120\n",
      "133/133 [==============================] - 29s 222ms/step - loss: 4.9426 - accuracy: 0.1496\n",
      "Epoch 8/120\n",
      "133/133 [==============================] - 30s 229ms/step - loss: 4.8041 - accuracy: 0.1652\n",
      "Epoch 9/120\n",
      "133/133 [==============================] - 30s 222ms/step - loss: 4.6585 - accuracy: 0.1824\n",
      "Epoch 10/120\n",
      "133/133 [==============================] - 40s 300ms/step - loss: 4.5172 - accuracy: 0.1953\n",
      "Epoch 11/120\n",
      "133/133 [==============================] - 35s 267ms/step - loss: 4.3783 - accuracy: 0.2107\n",
      "Epoch 12/120\n",
      "133/133 [==============================] - 36s 269ms/step - loss: 4.2366 - accuracy: 0.2311\n",
      "Epoch 13/120\n",
      "133/133 [==============================] - 35s 262ms/step - loss: 4.0963 - accuracy: 0.2542\n",
      "Epoch 14/120\n",
      "133/133 [==============================] - 27s 199ms/step - loss: 3.9675 - accuracy: 0.2750\n",
      "Epoch 15/120\n",
      "133/133 [==============================] - 27s 206ms/step - loss: 3.8358 - accuracy: 0.3009\n",
      "Epoch 16/120\n",
      "133/133 [==============================] - 25s 185ms/step - loss: 3.7114 - accuracy: 0.3266\n",
      "Epoch 17/120\n",
      "133/133 [==============================] - 26s 195ms/step - loss: 3.5775 - accuracy: 0.3504\n",
      "Epoch 18/120\n",
      "133/133 [==============================] - 24s 184ms/step - loss: 3.4533 - accuracy: 0.3664\n",
      "Epoch 19/120\n",
      "133/133 [==============================] - 26s 194ms/step - loss: 3.3294 - accuracy: 0.3874\n",
      "Epoch 20/120\n",
      "133/133 [==============================] - 28s 212ms/step - loss: 3.2135 - accuracy: 0.4116\n",
      "Epoch 21/120\n",
      "133/133 [==============================] - 30s 225ms/step - loss: 3.1004 - accuracy: 0.4286\n",
      "Epoch 22/120\n",
      "133/133 [==============================] - 35s 262ms/step - loss: 2.9809 - accuracy: 0.4482\n",
      "Epoch 23/120\n",
      "133/133 [==============================] - 37s 279ms/step - loss: 2.8753 - accuracy: 0.4637\n",
      "Epoch 24/120\n",
      "133/133 [==============================] - 44s 335ms/step - loss: 2.7590 - accuracy: 0.4840\n",
      "Epoch 25/120\n",
      "133/133 [==============================] - 42s 313ms/step - loss: 2.6440 - accuracy: 0.5040\n",
      "Epoch 26/120\n",
      "133/133 [==============================] - 47s 356ms/step - loss: 2.5432 - accuracy: 0.5179\n",
      "Epoch 27/120\n",
      "133/133 [==============================] - 42s 320ms/step - loss: 2.4399 - accuracy: 0.5372\n",
      "Epoch 28/120\n",
      "133/133 [==============================] - 42s 318ms/step - loss: 2.3417 - accuracy: 0.5530\n",
      "Epoch 29/120\n",
      "133/133 [==============================] - 29s 215ms/step - loss: 2.2421 - accuracy: 0.5827\n",
      "Epoch 30/120\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 2.1460 - accuracy: 0.5959\n",
      "Epoch 31/120\n",
      "133/133 [==============================] - 26s 193ms/step - loss: 2.0378 - accuracy: 0.6180\n",
      "Epoch 32/120\n",
      "133/133 [==============================] - 25s 185ms/step - loss: 1.9501 - accuracy: 0.6381\n",
      "Epoch 33/120\n",
      "133/133 [==============================] - 30s 226ms/step - loss: 1.8580 - accuracy: 0.6666\n",
      "Epoch 34/120\n",
      "133/133 [==============================] - 35s 263ms/step - loss: 1.7758 - accuracy: 0.6795\n",
      "Epoch 35/120\n",
      "133/133 [==============================] - 28s 214ms/step - loss: 1.6846 - accuracy: 0.6960\n",
      "Epoch 36/120\n",
      "133/133 [==============================] - 27s 207ms/step - loss: 1.6067 - accuracy: 0.7180\n",
      "Epoch 37/120\n",
      "133/133 [==============================] - 32s 241ms/step - loss: 1.5251 - accuracy: 0.7352\n",
      "Epoch 38/120\n",
      "133/133 [==============================] - 27s 200ms/step - loss: 1.4484 - accuracy: 0.7578\n",
      "Epoch 39/120\n",
      "133/133 [==============================] - 25s 191ms/step - loss: 1.3737 - accuracy: 0.7747\n",
      "Epoch 40/120\n",
      "133/133 [==============================] - 27s 200ms/step - loss: 1.2986 - accuracy: 0.8011\n",
      "Epoch 41/120\n",
      "133/133 [==============================] - 25s 189ms/step - loss: 1.2352 - accuracy: 0.8063\n",
      "Epoch 42/120\n",
      "133/133 [==============================] - 26s 196ms/step - loss: 1.1601 - accuracy: 0.8332\n",
      "Epoch 43/120\n",
      "133/133 [==============================] - 26s 195ms/step - loss: 1.0984 - accuracy: 0.8433\n",
      "Epoch 44/120\n",
      "133/133 [==============================] - 26s 194ms/step - loss: 1.0377 - accuracy: 0.8577\n",
      "Epoch 45/120\n",
      "133/133 [==============================] - 26s 195ms/step - loss: 0.9838 - accuracy: 0.8706\n",
      "Epoch 46/120\n",
      "133/133 [==============================] - 25s 186ms/step - loss: 0.9164 - accuracy: 0.8862\n",
      "Epoch 47/120\n",
      "133/133 [==============================] - 26s 195ms/step - loss: 0.8675 - accuracy: 0.8996\n",
      "Epoch 48/120\n",
      "133/133 [==============================] - 26s 196ms/step - loss: 0.8178 - accuracy: 0.9062\n",
      "Epoch 49/120\n",
      "133/133 [==============================] - 30s 226ms/step - loss: 0.7669 - accuracy: 0.9128\n",
      "Epoch 50/120\n",
      "133/133 [==============================] - 30s 227ms/step - loss: 0.7299 - accuracy: 0.9218\n",
      "Epoch 51/120\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.6801 - accuracy: 0.9295\n",
      "Epoch 52/120\n",
      "133/133 [==============================] - 26s 195ms/step - loss: 0.6343 - accuracy: 0.9387\n",
      "Epoch 53/120\n",
      "133/133 [==============================] - 26s 192ms/step - loss: 0.6101 - accuracy: 0.9416\n",
      "Epoch 54/120\n",
      "133/133 [==============================] - 27s 203ms/step - loss: 0.5673 - accuracy: 0.9434\n",
      "Epoch 55/120\n",
      "133/133 [==============================] - 25s 190ms/step - loss: 0.5384 - accuracy: 0.9491\n",
      "Epoch 56/120\n",
      "133/133 [==============================] - 25s 185ms/step - loss: 0.4952 - accuracy: 0.9550\n",
      "Epoch 57/120\n",
      "133/133 [==============================] - 30s 227ms/step - loss: 0.4679 - accuracy: 0.9564\n",
      "Epoch 58/120\n",
      "133/133 [==============================] - 27s 199ms/step - loss: 0.4399 - accuracy: 0.9630\n",
      "Epoch 59/120\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.4075 - accuracy: 0.9668\n",
      "Epoch 60/120\n",
      "133/133 [==============================] - 26s 196ms/step - loss: 0.3826 - accuracy: 0.9698\n",
      "Epoch 61/120\n",
      "133/133 [==============================] - 25s 187ms/step - loss: 0.3670 - accuracy: 0.9698\n",
      "Epoch 62/120\n",
      "133/133 [==============================] - 26s 198ms/step - loss: 0.3446 - accuracy: 0.9708\n",
      "Epoch 63/120\n",
      "133/133 [==============================] - 26s 193ms/step - loss: 0.3289 - accuracy: 0.9724\n",
      "Epoch 64/120\n",
      "133/133 [==============================] - 25s 188ms/step - loss: 0.3120 - accuracy: 0.9746\n",
      "Epoch 65/120\n",
      "133/133 [==============================] - 34s 260ms/step - loss: 0.2891 - accuracy: 0.9757\n",
      "Epoch 66/120\n",
      "133/133 [==============================] - 30s 224ms/step - loss: 0.2736 - accuracy: 0.9769\n",
      "Epoch 67/120\n",
      "133/133 [==============================] - 31s 231ms/step - loss: 0.2622 - accuracy: 0.9771\n",
      "Epoch 68/120\n",
      "133/133 [==============================] - 31s 231ms/step - loss: 0.2481 - accuracy: 0.9774\n",
      "Epoch 69/120\n",
      "133/133 [==============================] - 26s 195ms/step - loss: 0.2313 - accuracy: 0.9793\n",
      "Epoch 70/120\n",
      "133/133 [==============================] - 24s 177ms/step - loss: 0.2250 - accuracy: 0.9800\n",
      "Epoch 71/120\n",
      "133/133 [==============================] - 26s 195ms/step - loss: 0.2178 - accuracy: 0.9809\n",
      "Epoch 72/120\n",
      "133/133 [==============================] - 27s 205ms/step - loss: 0.2081 - accuracy: 0.9811\n",
      "Epoch 73/120\n",
      "133/133 [==============================] - 26s 193ms/step - loss: 0.2001 - accuracy: 0.9802\n",
      "Epoch 74/120\n",
      "133/133 [==============================] - 25s 186ms/step - loss: 0.1886 - accuracy: 0.9823\n",
      "Epoch 75/120\n",
      "133/133 [==============================] - 25s 185ms/step - loss: 0.1786 - accuracy: 0.9823\n",
      "Epoch 76/120\n",
      "133/133 [==============================] - 26s 199ms/step - loss: 0.1784 - accuracy: 0.9823\n",
      "Epoch 77/120\n",
      "133/133 [==============================] - 26s 194ms/step - loss: 0.1632 - accuracy: 0.9830\n",
      "Epoch 78/120\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.1578 - accuracy: 0.9833\n",
      "Epoch 79/120\n",
      "133/133 [==============================] - 28s 208ms/step - loss: 0.1517 - accuracy: 0.9830\n",
      "Epoch 80/120\n",
      "133/133 [==============================] - 25s 186ms/step - loss: 0.1483 - accuracy: 0.9840\n",
      "Epoch 81/120\n",
      "133/133 [==============================] - 26s 197ms/step - loss: 0.1455 - accuracy: 0.9837\n",
      "Epoch 82/120\n",
      "133/133 [==============================] - 25s 185ms/step - loss: 0.1785 - accuracy: 0.9753\n",
      "Epoch 83/120\n",
      "133/133 [==============================] - 26s 198ms/step - loss: 0.2022 - accuracy: 0.9703\n",
      "Epoch 84/120\n",
      "133/133 [==============================] - 25s 189ms/step - loss: 0.2010 - accuracy: 0.9708\n",
      "Epoch 85/120\n",
      "133/133 [==============================] - 28s 209ms/step - loss: 0.1678 - accuracy: 0.9767\n",
      "Epoch 86/120\n",
      "133/133 [==============================] - 25s 188ms/step - loss: 0.1481 - accuracy: 0.9830\n",
      "Epoch 87/120\n",
      "133/133 [==============================] - 25s 189ms/step - loss: 0.1268 - accuracy: 0.9835\n",
      "Epoch 88/120\n",
      "133/133 [==============================] - 26s 195ms/step - loss: 0.1181 - accuracy: 0.9847\n",
      "Epoch 89/120\n",
      "133/133 [==============================] - 25s 189ms/step - loss: 0.1128 - accuracy: 0.9849\n",
      "Epoch 90/120\n",
      "133/133 [==============================] - 25s 186ms/step - loss: 0.1124 - accuracy: 0.9840\n",
      "Epoch 91/120\n",
      "133/133 [==============================] - 26s 193ms/step - loss: 0.1064 - accuracy: 0.9854\n",
      "Epoch 92/120\n",
      "133/133 [==============================] - 25s 184ms/step - loss: 0.1046 - accuracy: 0.9849\n",
      "Epoch 93/120\n",
      "133/133 [==============================] - 28s 211ms/step - loss: 0.1078 - accuracy: 0.9833\n",
      "Epoch 94/120\n",
      "133/133 [==============================] - 26s 195ms/step - loss: 0.1052 - accuracy: 0.9854\n",
      "Epoch 95/120\n",
      "133/133 [==============================] - 26s 195ms/step - loss: 0.1049 - accuracy: 0.9842\n",
      "Epoch 96/120\n",
      "133/133 [==============================] - 27s 202ms/step - loss: 0.0989 - accuracy: 0.9847\n",
      "Epoch 97/120\n",
      "133/133 [==============================] - 26s 194ms/step - loss: 0.0973 - accuracy: 0.9847\n",
      "Epoch 98/120\n",
      "133/133 [==============================] - 26s 197ms/step - loss: 0.0950 - accuracy: 0.9856\n",
      "Epoch 99/120\n",
      "133/133 [==============================] - 25s 186ms/step - loss: 0.0930 - accuracy: 0.9849\n",
      "Epoch 100/120\n",
      "133/133 [==============================] - 29s 218ms/step - loss: 0.0949 - accuracy: 0.9837\n",
      "Epoch 101/120\n",
      "133/133 [==============================] - 27s 199ms/step - loss: 0.0909 - accuracy: 0.9852\n",
      "Epoch 102/120\n",
      "133/133 [==============================] - 27s 202ms/step - loss: 0.0963 - accuracy: 0.9840\n",
      "Epoch 103/120\n",
      "133/133 [==============================] - 25s 189ms/step - loss: 0.1117 - accuracy: 0.9826\n",
      "Epoch 104/120\n",
      "133/133 [==============================] - 26s 194ms/step - loss: 0.1380 - accuracy: 0.9769\n",
      "Epoch 105/120\n",
      "133/133 [==============================] - 26s 192ms/step - loss: 0.1484 - accuracy: 0.9736\n",
      "Epoch 106/120\n",
      "133/133 [==============================] - 28s 209ms/step - loss: 0.1273 - accuracy: 0.9776\n",
      "Epoch 107/120\n",
      "133/133 [==============================] - 27s 199ms/step - loss: 0.1067 - accuracy: 0.9826\n",
      "Epoch 108/120\n",
      "133/133 [==============================] - 26s 193ms/step - loss: 0.0951 - accuracy: 0.9842\n",
      "Epoch 109/120\n",
      "133/133 [==============================] - 25s 191ms/step - loss: 0.0895 - accuracy: 0.9856\n",
      "Epoch 110/120\n",
      "133/133 [==============================] - 27s 202ms/step - loss: 0.0875 - accuracy: 0.9840\n",
      "Epoch 111/120\n",
      "133/133 [==============================] - 26s 199ms/step - loss: 0.0840 - accuracy: 0.9852\n",
      "Epoch 112/120\n",
      "133/133 [==============================] - 25s 184ms/step - loss: 0.0817 - accuracy: 0.9852\n",
      "Epoch 113/120\n",
      "133/133 [==============================] - 27s 200ms/step - loss: 0.0820 - accuracy: 0.9856\n",
      "Epoch 114/120\n",
      "133/133 [==============================] - 25s 186ms/step - loss: 0.0820 - accuracy: 0.9849\n",
      "Epoch 115/120\n",
      "133/133 [==============================] - 26s 196ms/step - loss: 0.0801 - accuracy: 0.9859\n",
      "Epoch 116/120\n",
      "133/133 [==============================] - 25s 189ms/step - loss: 0.0797 - accuracy: 0.9849\n",
      "Epoch 117/120\n",
      "133/133 [==============================] - 25s 190ms/step - loss: 0.0787 - accuracy: 0.9852\n",
      "Epoch 118/120\n",
      "133/133 [==============================] - 29s 220ms/step - loss: 0.0811 - accuracy: 0.9854\n",
      "Epoch 119/120\n",
      "133/133 [==============================] - 26s 196ms/step - loss: 0.0775 - accuracy: 0.9859\n",
      "Epoch 120/120\n",
      "133/133 [==============================] - 26s 197ms/step - loss: 0.0771 - accuracy: 0.9861\n"
     ]
    }
   ],
   "source": [
    "D = 768\n",
    "\n",
    "T = train_X.shape[1]\n",
    "i = Input(shape=(T,))\n",
    "x = Embedding(V + 1, D)(i)\n",
    "x = Dropout(0.1)(x)\n",
    "x = LSTM(100, return_sequences=True)(x)\n",
    "x = LSTM(100)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(V, activation=\"softmax\")(x)\n",
    "lstm_model = Model(i, x)\n",
    "lstm_model.summary()\n",
    "\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "lstm_model.compile(optimizer=adam, metrics=[\"accuracy\"], loss=\"categorical_crossentropy\")\n",
    "\n",
    "lstm_r = lstm_model.fit(train_X, train_y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6cf9b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 29, 512)           1693696   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 15, 512)           3932672   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 15, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 8, 256)            1048832   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 500)               1014000   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3307)              1656807   \n",
      "=================================================================\n",
      "Total params: 9,346,007\n",
      "Trainable params: 9,346,007\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/220\n",
      "133/133 [==============================] - 97s 701ms/step - loss: 6.8471 - accuracy: 0.0815\n",
      "Epoch 2/220\n",
      "133/133 [==============================] - 88s 660ms/step - loss: 5.9979 - accuracy: 0.1110\n",
      "Epoch 3/220\n",
      "133/133 [==============================] - 82s 618ms/step - loss: 5.7803 - accuracy: 0.1291\n",
      "Epoch 4/220\n",
      "133/133 [==============================] - 94s 704ms/step - loss: 5.6568 - accuracy: 0.1291\n",
      "Epoch 5/220\n",
      "133/133 [==============================] - 85s 640ms/step - loss: 5.5257 - accuracy: 0.1301\n",
      "Epoch 6/220\n",
      "133/133 [==============================] - 86s 650ms/step - loss: 5.3918 - accuracy: 0.1345\n",
      "Epoch 7/220\n",
      "133/133 [==============================] - 95s 718ms/step - loss: 5.2616 - accuracy: 0.1388\n",
      "Epoch 8/220\n",
      "133/133 [==============================] - 94s 710ms/step - loss: 5.1448 - accuracy: 0.1447\n",
      "Epoch 9/220\n",
      "133/133 [==============================] - 84s 626ms/step - loss: 5.0250 - accuracy: 0.1487\n",
      "Epoch 10/220\n",
      "133/133 [==============================] - 81s 612ms/step - loss: 4.9233 - accuracy: 0.1616\n",
      "Epoch 11/220\n",
      "133/133 [==============================] - 88s 663ms/step - loss: 4.8299 - accuracy: 0.1673\n",
      "Epoch 12/220\n",
      "133/133 [==============================] - 84s 631ms/step - loss: 4.7339 - accuracy: 0.1751\n",
      "Epoch 13/220\n",
      "133/133 [==============================] - 84s 628ms/step - loss: 4.6471 - accuracy: 0.1831\n",
      "Epoch 14/220\n",
      "133/133 [==============================] - 86s 649ms/step - loss: 4.5520 - accuracy: 0.1972\n",
      "Epoch 15/220\n",
      "133/133 [==============================] - 89s 670ms/step - loss: 4.4653 - accuracy: 0.1972\n",
      "Epoch 16/220\n",
      "133/133 [==============================] - 80s 604ms/step - loss: 4.3922 - accuracy: 0.2168\n",
      "Epoch 17/220\n",
      "133/133 [==============================] - 109s 825ms/step - loss: 4.3055 - accuracy: 0.2283\n",
      "Epoch 18/220\n",
      "133/133 [==============================] - 97s 726ms/step - loss: 4.2311 - accuracy: 0.2328\n",
      "Epoch 19/220\n",
      "133/133 [==============================] - 87s 658ms/step - loss: 4.1507 - accuracy: 0.2493\n",
      "Epoch 20/220\n",
      "133/133 [==============================] - 81s 605ms/step - loss: 4.0726 - accuracy: 0.2542\n",
      "Epoch 21/220\n",
      "133/133 [==============================] - 83s 624ms/step - loss: 4.0082 - accuracy: 0.2644\n",
      "Epoch 22/220\n",
      "133/133 [==============================] - 94s 707ms/step - loss: 3.9198 - accuracy: 0.2813\n",
      "Epoch 23/220\n",
      "133/133 [==============================] - 96s 715ms/step - loss: 3.8556 - accuracy: 0.2828\n",
      "Epoch 24/220\n",
      "133/133 [==============================] - 84s 635ms/step - loss: 3.7787 - accuracy: 0.2910\n",
      "Epoch 25/220\n",
      " 87/133 [==================>...........] - ETA: 37s - loss: 3.6539 - accuracy: 0.3132"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-40d2eebfa95b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mcnn_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m220\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "D = 512\n",
    "\n",
    "T = train_X.shape[1]\n",
    "i = Input(shape=(T,))\n",
    "x = Embedding(V + 1, D)(i)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(filters=512, kernel_size=15)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(filters=256, kernel_size=8)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Bidirectional(LSTM(250))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(V, activation=\"softmax\")(x)\n",
    "cnn_model = Model(i, x)\n",
    "cnn_model.summary()\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "cnn_model.compile(optimizer=adam, metrics=[\"accuracy\"], loss=\"categorical_crossentropy\")\n",
    "\n",
    "cnn_r = cnn_model.fit(train_X, train_y, epochs=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bcd43e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb889c2aac0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rnn_r.history['loss'], label=\"SimpleRNN Loss\")\n",
    "plt.plot(lstm_r.history['loss'], label=\"LSTM Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9133bd6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn_r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-95592643ee8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_r\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SimpleRNN accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_r\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LSTM accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_r\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CNN+LSTM accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn_r' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rnn_r.history['accuracy'], label=\"SimpleRNN accuracy\")\n",
    "plt.plot(lstm_r.history['accuracy'], label=\"LSTM accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b59fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rap(model, artists_bars, length_of_bar=10, length_of_rap=20, min_score_threshold=-0.2, max_score_threshold=0.2, tries=5):\n",
    "    artists_avg_readability = calc_readability(artists_bars)\n",
    "    artists_avg_rhyme_idx = calc_rhyme_density(artists_bars)\n",
    "    fire_rap = []\n",
    "    cur_tries = 0\n",
    "    candidate_bars = []\n",
    "\n",
    "    while len(fire_rap) < length_of_rap:\n",
    "        seed_phrase = markov_model.make_sentence(tries=500).split(\" \")\n",
    "        seed_phrase = \" \".join(seed_phrase[:3])\n",
    "        cur_tries += 1\n",
    "        bar = generate_bar(seed_phrase, model, rand.randrange(4, length_of_bar))\n",
    "        bar_score = score_bar(bar, artist_lyrics, artists_avg_readability, artists_avg_rhyme_idx) \n",
    "        candidate_bars.append((bar_score, bar))\n",
    "\n",
    "    if bar_score <= max_score_threshold and bar_score >= min_score_threshold:\n",
    "        fire_rap.append(bar)\n",
    "        cur_tries = 0\n",
    "    print(\"Generated Bar: \", len(fire_rap))\n",
    "\n",
    "    if cur_tries >= tries:\n",
    "        lowest_score = np.Infinity\n",
    "        best_bar = \"\"\n",
    "        for bar in candidate_bars:\n",
    "            if bar[0] < lowest_score:\n",
    "                best_bar = bar[1]\n",
    "                candidate_bars = []\n",
    "      \n",
    "    print(\"Generated Bar: \", len(fire_rap))\n",
    "    fire_rap.append(best_bar)\n",
    "    cur_tries = 0\n",
    "      \n",
    "    print(\"Generated rap with avg rhyme density: \", calc_rhyme_density(fire_rap), \"and avg readability of: \", calc_readability(fire_rap))\n",
    "    return fire_rap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e32bd3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bar(seed_phrase, model, length_of_bar):\n",
    "    for i in range(length_of_bar):\n",
    "        seed_tokens = pad_sequences(tokenizer.texts_to_sequences([seed_phrase]), maxlen=29)\n",
    "        output_p = model.predict(seed_tokens)\n",
    "        output_word = np.argmax(output_p, axis=1)[0]-1\n",
    "        seed_phrase += \" \" + str(list(tokenizer.word_index.items())[output_word][0])\n",
    "    return seed_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09bded92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_bars(input_bar, artists_bars):\n",
    "  '''\n",
    "    input_bars are the fire bars our AI generates\n",
    "    artists_bars are the original bars for the artist\n",
    "\n",
    "    The lower the score the better! We want unique bars\n",
    "  '''\n",
    "  # Converts sentences to matrix of token counts\n",
    "    avg_dist = 0\n",
    "    total_counted = 0\n",
    "    for bar in artists_bars:\n",
    "    v = CountVectorizer()\n",
    "    # Vectorize the sentences\n",
    "    word_vector = v.fit_transform([input_bar, bar])\n",
    "    # Compute the cosine distance between the sentence vectors\n",
    "    cos_dist = 1-pdist(word_vector.toarray(), 'cosine')[0]\n",
    "    if not math.isnan(cos_dist):\n",
    "        avg_dist += 1-pdist(word_vector.toarray(), 'cosine')[0]\n",
    "        total_counted += 1\n",
    "    return avg_dist/total_counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87b51e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Rhyme density is calculated by taking the number of rhymed syllables and divide it by total number of syllables'''\n",
    "def calc_rhyme_density(bars):\n",
    "    total_syllables = 0\n",
    "    rhymed_syllables = 0\n",
    "    for bar in bars:\n",
    "        for word in bar.split():\n",
    "            p = pronouncing.phones_for_word(word)\n",
    "            if len(p) == 0:\n",
    "                break\n",
    "            syllables = pronouncing.syllable_count(p[0])\n",
    "            total_syllables += syllables\n",
    "            has_rhyme = False\n",
    "    for rhyme in pronouncing.rhymes(word):\n",
    "        if has_rhyme:\n",
    "            break\n",
    "        for idx, r_bar in enumerate(bars):\n",
    "            if idx > 4:\n",
    "                break\n",
    "            if rhyme in r_bar:\n",
    "                rhymed_syllables += syllables\n",
    "                has_rhyme = True\n",
    "                break\n",
    "    return rhymed_syllables/total_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12da3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_readability(input_bars):\n",
    "    avg_readability = 0\n",
    "    for bar in input_bars:\n",
    "        avg_readability += textstat.automated_readability_index(bar)\n",
    "    return avg_readability / len(input_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76e18978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_bar(input_bar, artists_bars, artists_avg_readability, artists_avg_rhyme_idx):\n",
    "    gen_readability = textstat.automated_readability_index(input_bar)\n",
    "    gen_rhyme_idx = calc_rhyme_density(input_bar)\n",
    "    comp_bars = compare_bars(input_bar, artists_bars)\n",
    "\n",
    "    # Scores based off readability, rhyme index, and originality. The lower the score the better.\n",
    "    bar_score = (artists_avg_readability - gen_readability) + (artists_avg_rhyme_idx - gen_rhyme_idx) + comp_bars\n",
    "    return bar_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cb53489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Bar:  1\n",
      "Generated Bar:  2\n",
      "Generated Bar:  3\n",
      "Generated Bar:  4\n",
      "Generated Bar:  5\n",
      "Generated Bar:  6\n",
      "Generated Bar:  7\n",
      "Generated Bar:  8\n",
      "Generated Bar:  9\n",
      "Generated Bar:  10\n",
      "Generated Bar:  11\n",
      "Generated Bar:  12\n",
      "Generated Bar:  13\n",
      "Generated Bar:  14\n",
      "Generated Bar:  15\n",
      "Generated Bar:  16\n",
      "Generated Bar:  17\n",
      "Generated Bar:  18\n",
      "Generated Bar:  19\n",
      "Generated Bar:  20\n",
      "Generated rap with avg rhyme density:  0.39097744360902253 and avg readability of:  2.3999999999999995\n",
      "Rap Generated with SimpleRNN:\n",
      "You would look see you shawty ones that jump jump\n",
      "'Cause you're a go slow song myself there\n",
      "You know that mu'fucka and wishin' now man no\n",
      "Not even when everything slow for me though on me\n",
      "We even talked away eh dressing stone soon now on\n",
      "Girl don't treat naps me baby yeah yeah yeah yeah\n",
      "There for me, though thing me yeah yeah yeah yeah\n",
      "****, I know yeah yeah yeah yeah yeah yeah\n",
      "Please, please do me girl true yeah yeah yeah\n",
      "For all my people back here tonight again woo\n",
      "You send shots, though game play it too life some\n",
      "But then got everything my name yeah\n",
      "They don't really play it yeah yeah yeah yeah\n",
      "Wow, Im honored some you die before\n",
      "You love me though thing yeah yeah yeah yeah yeah\n",
      "She knew that time i everything say\n",
      "Girl don't treat naps me baby yeah yeah yeah yeah\n",
      "It's my birthday, my money yeah yeah\n",
      "But my mind tonight home famous here me yeah yeah\n",
      "Gotta watch that long i real stone stay down\n",
      "\n",
      "Generated Bar:  1\n",
      "Generated Bar:  2\n",
      "Generated Bar:  3\n",
      "Generated Bar:  4\n",
      "Generated Bar:  5\n",
      "Generated Bar:  6\n",
      "Generated Bar:  7\n",
      "Generated Bar:  8\n",
      "Generated Bar:  9\n",
      "Generated Bar:  10\n",
      "Generated Bar:  11\n",
      "Generated Bar:  12\n",
      "Generated Bar:  13\n",
      "Generated Bar:  14\n",
      "Generated Bar:  15\n",
      "Generated Bar:  16\n",
      "Generated Bar:  17\n",
      "Generated Bar:  18\n",
      "Generated Bar:  19\n",
      "Generated Bar:  20\n",
      "Generated rap with avg rhyme density:  0.4225352112676056 and avg readability of:  2.375\n",
      "Rap Generated with LSTM:\n",
      "Tell me how body quick to be different though\n",
      "Drapes closed, I different up now me\n",
      "You would look mortified is knew it ohhh ohhh\n",
      "Shots came, I deadly due huh working\n",
      "Trust me girl, on me well everything\n",
      "Drapes closed, I different up now me\n",
      "Rode that **** true true me yeah yeah\n",
      "'Cause you're a okay yeah yeah yeah yeah yeah\n",
      "Drapes closed, I different up now me\n",
      "When I was talkin' speakin' some new\n",
      "500 million, I see you feelings nah it though you\n",
      "When I was talkin' speakin' some new\n",
      "When I was talkin' speakin' some new\n",
      "This is not speakin' inspirin' to her flow me\n",
      "This is not speakin' inspirin' to her flow me\n",
      "It's my birthday, clean home mention up at to\n",
      "So watch how mu'fucka claim good back you\n",
      "And that's why woah yeah yeah yeah yeah yeah yeah\n",
      "Girl, how 'bout now girl nervous mind had\n",
      "You make me swanging about you changed it girl me\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_sentence = markov_model.make_sentence(tries=100).split(\" \")\n",
    "seed_sentence = \" \".join(seed_sentence[:5])\n",
    "\n",
    "rnn = generate_rap(rnn_model, artist_lyrics, length_of_bar = 8, tries=100)\n",
    "\n",
    "print(\"Rap Generated with SimpleRNN:\")\n",
    "for line in rnn:\n",
    "    print(line)\n",
    "print()\n",
    "\n",
    "lstm = generate_rap(lstm_model, artist_lyrics, length_of_bar = 8, tries=100)\n",
    "\n",
    "print(\"Rap Generated with LSTM:\")\n",
    "for line in lstm:\n",
    "    print(line)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15437b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
